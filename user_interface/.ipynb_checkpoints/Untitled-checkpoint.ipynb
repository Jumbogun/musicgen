{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GenThread(QThread):  # 线程1\n",
    "    def __init__(self,  arg, gen_model, pixelcnn, device):\n",
    "        super().__init__()\n",
    "        self.gen_model = gen_model.eval()\n",
    "        self.pixelcnn = pixelcnn.eval()\n",
    "        self.device = device\n",
    "        \n",
    "        self.program_nums     = args[\"program_nums\"]\n",
    "        self.is_drum          = args[\"is_drum\"]\n",
    "        self.tempo            = args[\"tempo\"]\n",
    "        self.n_tracks         = args[\"n_tracks\"]\n",
    "        self.n_pitches        = args[\"n_pitches\"]\n",
    "        self.n_verses         = args[\"n_verses\"]\n",
    "        self.lowest_pitch     = args[\"lowest_pitch\"]\n",
    "        self.n_measures       = args[\"n_measures\"]\n",
    "        self.beat_resolution  = args[\"beat_resolution\"]\n",
    "        self.batch_size       = args[\"batch_size\"]\n",
    "        self.decay            = args[\"decay\"]\n",
    "        self.commitment_cost  = args[\"commitment_cost\"]\n",
    "        self.latent_w         = args[\"latent_w\"]\n",
    "        self.latent_h         = args[\"latent_h\"]\n",
    "        self.latent_dim       = args[\"latent_dim\"]\n",
    "        self.embedding_dim    = args[\"embedding_dim\"]\n",
    "        self.num_embeddings   = args[\"num_embeddings\"]\n",
    "        \n",
    "        self.GMutex = QMutex()\n",
    "    def get_output(self, new_output = True):\n",
    "        #get the return from run \n",
    "        if(new_output):\n",
    "            self.pr = self.generate()\n",
    "            self.im = self.pr2im1(self.pr)\n",
    "            self.im_w = self.im.shape[1]     \n",
    "            self.im = np.concatenate([self.im, np.zeros([self.im.shape[0], self.dw, 3], np.int32)], axis = 1)\n",
    "            self.process_bar.setMaximum(self.im_w)\n",
    "            self.set_cur_pixel(0, False)\n",
    "            self.waves = self.get_wav(self.pr, self.im_w // self.time_step)\n",
    "        return self.pr, self.waves, self.im_w,  self.im_bg\n",
    "        \n",
    "    def run(self):\n",
    "        pass\n",
    "        \n",
    "    def generate(self):\n",
    "        batch_size = 1\n",
    "        Z_track, Z_w, Z_h = self.n_tracks, self.n_verses * self.latent_w, self.latent_h\n",
    "        rand_idx = torch.autograd.Variable(torch.multinomial(torch.rand(batch_size * Z_track * Z_w * Z_h, self.embedding_dim),1)).squeeze().long().cuda()\n",
    "        rand_Z = self.gen_model.VQ._embedding.weight[rand_idx].view(-1, Z_track, Z_h, Z_w, self.embedding_dim).permute(0, 4, 1, 2, 3)\n",
    "        starting_point = 0\n",
    "        for i in range(Z_w):\n",
    "                if(i < starting_point):\n",
    "                    continue\n",
    "                with torch.no_grad():\n",
    "                    logit = self.pixelcnn(rand_Z)\n",
    "                prob = F.softmax(logit, dim = 1).data\n",
    "                prob = prob[:,:,:,:, i].permute(0, 2, 3, 1).reshape(-1, self.num_embeddings)\n",
    "                idx = torch.multinomial(prob,1).reshape(logit.shape[0], logit.shape[2],logit.shape[3])\n",
    "                #idx = prob[:,:,4,4].argmax(dim = 1).squeeze()\n",
    "                \n",
    "                for t in range(self.n_tracks):\n",
    "                    print(self.tracks_selection)\n",
    "                    if(not self.tracks_selection[t]):\n",
    "                        idx[:, t] = 3\n",
    "                \n",
    "                rand_Z[:,:,:,:,i] = self.gen_model.VQ._embedding.weight[idx].reshape(logit.shape[0], logit.shape[2],logit.shape[3], self.embedding_dim).permute(0, 3, 1, 2)\n",
    "\n",
    "        x = rand_Z.reshape(batch_size, self.embedding_dim, self.n_tracks, self.latent_h, self.n_verses, self.latent_w)\n",
    "        x = x.permute(0, 4, 2, 1, 5, 3).contiguous()\n",
    "        gen_bar = self.gen_model.decoder(x[0])\n",
    "\n",
    "        pr = gen_bar.cpu().detach().numpy().reshape(self.n_verses, self.n_tracks, self.resolution, self.n_pitches).transpose(0, 2, 3, 1)\n",
    "        pr = np.stack([pr] * self.time_step, axis = 2)\n",
    "        pr = pr.reshape(pr.shape[0], -1, pr.shape[3], pr.shape[4])\n",
    "        return pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "perfect-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "from pyaudio import PyAudio\n",
    "import sys\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pursuant-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {    \"program_nums\"   :   [24, 2, 26, 87, 89],\n",
    "    \"is_drum\"        :   [True, False, False, False, False],\n",
    "    \"tempo\"          :  180.0,\n",
    "    \"n_tracks\"       :    5,\n",
    "    \"n_pitches\"      :   72,\n",
    "    \"n_verses\"       :   12,\n",
    "    \"lowest_pitch\"   :   24,\n",
    "    \"n_measures\"     :    4,\n",
    "    \"beat_resolution\":    4,\n",
    "    \"batch_size\"     :    1,\n",
    "    \"decay\"          :    0.99,\n",
    "    \"commitment_cost\":    0.25,\n",
    "    \"latent_w\"       :    4,\n",
    "    \"latent_h\"       :    6,\n",
    "    \"latent_dim\"     :    8,\n",
    "    \"embedding_dim\"  :    8,\n",
    "    \"num_embeddings\" : 2048,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "generous-effort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"beat_resolution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "musical-speed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.program_nums     = args[\"program_nums\"]\n",
      "self.is_drum          = args[\"is_drum\"]\n",
      "self.tempo            = args[\"tempo\"]\n",
      "self.n_tracks         = args[\"n_tracks\"]\n",
      "self.n_pitches        = args[\"n_pitches\"]\n",
      "self.n_verses         = args[\"n_verses\"]\n",
      "self.lowest_pitch     = args[\"lowest_pitch\"]\n",
      "self.n_measures       = args[\"n_measures\"]\n",
      "self.beat_resolution  = args[\"beat_resolution\"]\n",
      "self.batch_size       = args[\"batch_size\"]\n",
      "self.decay            = args[\"decay\"]\n",
      "self.commitment_cost  = args[\"commitment_cost\"]\n",
      "self.latent_w         = args[\"latent_w\"]\n",
      "self.latent_h         = args[\"latent_h\"]\n",
      "self.latent_dim       = args[\"latent_dim\"]\n",
      "self.embedding_dim    = args[\"embedding_dim\"]\n",
      "self.num_embeddings   = args[\"num_embeddings\"]\n"
     ]
    }
   ],
   "source": [
    "for k in list(tmp.keys()):\n",
    "    print(f'self.{k:16} = args[\"{k}\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-courtesy",
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.program_nums     = args[\"program_nums\"]\n",
    "        self.is_drum          = args[\"is_drum\"]\n",
    "        self.tempo            = args[\"tempo\"]\n",
    "        self.n_tracks         = args[\"n_tracks\"]\n",
    "        self.n_pitches        = args[\"n_pitches\"]\n",
    "        self.n_verses         = args[\"n_verses\"]\n",
    "        self.lowest_pitch     = args[\"lowest_pitch\"]\n",
    "        self.n_measures       = args[\"n_measures\"]\n",
    "        self.beat_resolution  = args[\"beat_resolution\"]\n",
    "        self.batch_size       = args[\"batch_size\"]\n",
    "        self.decay            = args[\"decay\"]\n",
    "        self.commitment_cost  = args[\"commitment_cost\"]\n",
    "        self.latent_w         = args[\"latent_w\"]\n",
    "        self.latent_h         = args[\"latent_h\"]\n",
    "        self.latent_dim       = args[\"latent_dim\"]\n",
    "        self.embedding_dim    = args[\"embedding_dim\"]\n",
    "        self.num_embeddings   = args[\"num_embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "independent-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_logo():\n",
    "    pr = [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
    "         ]] * 3\n",
    "\n",
    "    pr = np.array(pr, np.int32).transpose(1, 2, 0) * 255 \n",
    "    pr = pr + np.array([9, 48, 0])\n",
    "    pr = np.minimum(pr, 255)\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mathematical-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_logo():\n",
    "    pr = [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ],\n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
    "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ],\n",
    "         ]] * 3\n",
    "\n",
    "    pr = 1 - np.array(pr, np.int32).transpose(1, 2, 0)\n",
    "    \n",
    "    pr = pr * np.array([9, 48, 0])\n",
    "    pr = np.minimum(pr, 255)\n",
    "    return pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "artistic-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from ipywidgets import interact, IntSlider\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "from pathlib import Path\n",
    "import math\n",
    "import IPython.display\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track\n",
    "from tqdm.notebook import tqdm\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "modern-threat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pretty_midi/pretty_midi.py:97: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pm  = pretty_midi.PrettyMIDI(\"63.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "conservative-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "?pm.fluidsynth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "weird-liver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWidget{color:rgb(23, 102, 36)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "track_color = np.array([[209, 174, 116], [23, 102, 36], [196, 173, 63], [164, 25, 25], [58, 37, 167]], np.int32) \n",
    "i = 1\n",
    "print(\"QWidget{color:rgb\" + f\"({track_color[i][0]:d}, {track_color[i][1]:d}, {track_color[i][2]:d})\" + \"}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "supported-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4791887a00>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(init_logo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "streaming-vaccine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "promotional-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "               [0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "               [0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "               [0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "               [0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              ],\n",
    "             [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "               [0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "               [0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "               [0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              ],\n",
    "             [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "               [0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "               [0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "               [0, 0, 1, 1, 1, 1, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "              ],\n",
    "             ]\n",
    "pr = np.array(pr, np.int32).transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "saved-liberal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 10, 3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "designed-programmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 10, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 10\n",
    "pr = np.stack([pr] * scale, axis = 1)\n",
    "pr = pr.reshape( -1, pr.shape[2], pr.shape[3])\n",
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "corrected-kingdom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 100, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 10\n",
    "pr = np.stack([pr] * scale, axis = 2)\n",
    "pr = pr.reshape(pr.shape[0], -1, pr.shape[-1])\n",
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "trying-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mighty-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "departmental-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        track_color = np.array([[209, 174, 116], [23, 102, 36], [164, 50, 50]], np.int32)\n",
    "        im = (pr > 0.5).astype(np.int32)\n",
    "        ret = np.ones([im.shape[0], im.shape[1], 3], np.int32) * 19\n",
    "        for i in range(7):\n",
    "            ret[:, 4 * i] = 10 \n",
    "        for i in range(3):\n",
    "            tmp = np.stack([pr[..., i]] * 3, axis = -1) * track_color[i]\n",
    "            ret += tmp\n",
    "        ret = np.minimum(ret, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "informal-harris",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f35fcc1d6d0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-fleet",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "track_color = np.array([[75, 199, 134], [137, 137, 137], [164, 25, 25]], np.int32)\n",
    "\n",
    "im = (pr > 0.5).astype(np.int32)\n",
    "\n",
    "ret = np.zeros([im.shape[0], im.shape[1], 3], np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eligible-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pypianoroll as pr\n",
    "import pretty_midi\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models  \n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import Parameter\n",
    "import shutil\n",
    "from util import *\n",
    "import time\n",
    "import qtawesome\n",
    "import sys\n",
    "\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "QSlider.sliderPosition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "             QSlider::add-page:Horizontal\n",
    "             {     \n",
    "                background-color: rgb(87, 97, 106);\n",
    "                height:4px;\n",
    "             }\n",
    "             QSlider::sub-page:Horizontal \n",
    "            {\n",
    "                background-color:qlineargradient(spread:pad, x1:0, y1:0, x2:1, y2:0, stop:0 rgba(231,80,229, 255), stop:1 rgba(7,208,255, 255));\n",
    "                height:4px;\n",
    "             }\n",
    "            QSlider::groove:Horizontal \n",
    "            {\n",
    "                background:transparent;\n",
    "                height:6px;\n",
    "            }\n",
    "            QSlider::handle:Horizontal \n",
    "            {\n",
    "                height: 30px;\n",
    "                width:8px;\n",
    "                border-image: url(:/images/ic_music_thumb.png);\\\n",
    "                margin: -8 0px; \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "QCheckBox {\n",
    "    color:red;\n",
    "    background-color:rgb(101,101,101);\n",
    "}\n",
    "\n",
    "QCheckBox::indicator {\n",
    "    /* 选择框尺寸 */\n",
    "    width:13px;\n",
    "    height:13px;\n",
    "}\n",
    "\n",
    "QCheckBox::indicator:unchecked\n",
    "{\n",
    "    border-image:url(:/images/checkbox.png) 0 39 0 0;\n",
    "}\n",
    "QCheckBox::indicator:unchecked:hover\n",
    "{\n",
    "    border-image:url(:/images/checkbox.png) 0 26 0 13;\n",
    "}\n",
    "QCheckBox::indicator:unchecked:pressed\n",
    "{\n",
    "    border-image:url(:/images/checkbox.png) 0 13 0 26;\n",
    "}\n",
    "QCheckBox::indicator:checked\n",
    "{\n",
    "    border-image:url(:/images/checkbox.png) 0 0 0 39;\n",
    "}\n",
    "QCheckBox::indicator:checked:hover {\n",
    "    image:url(:/images/111.bmp);\n",
    "}\n",
    "\n",
    "QCheckBox::indicator:checked:pressed {\n",
    "    image:url(:/images/222.bmp);\n",
    "}\n",
    "\n",
    "QCheckBox::indicator:indeterminate:hover {\n",
    "    image:url(:/images/333.bmp);\n",
    "}\n",
    "\n",
    "QCheckBox::indicator:indeterminate:pressed {\n",
    "    image:url(:/images/444.bmp);\n",
    "}\n",
    "\n",
    "\n",
    "————————————————\n",
    "版权声明：本文为CSDN博主「急行的小船」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n",
    "原文链接：https://blog.csdn.net/wzs250969969/article/details/78457749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "QComboBox().setFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-helen",
   "metadata": {},
   "outputs": [],
   "source": [
    "QComboBox().currentData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.bottom_widget.setStyleSheet('''\n",
    "            QWidget#right_widget{\n",
    "                color:#232C51;\n",
    "                background:white;\n",
    "                border-top:1px solid darkGray;\n",
    "                border-bottom:1px solid darkGray;\n",
    "                border-right:1px solid darkGray;\n",
    "                border-top-right-radius:10px;\n",
    "                border-bottom-right-radius:10px;\n",
    "            }\n",
    "            QLabel#right_lable{\n",
    "                border:none;\n",
    "                font-size:16px;\n",
    "                font-weight:700;\n",
    "                font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
    "            }\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "recreational-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.left_widget.setStyleSheet('''\n",
    "            QPushButton{border:none;color:white;}\n",
    "            QPushButton#left_label{\n",
    "                border:none;\n",
    "                border-bottom:1px solid white;\n",
    "                font-size:18px;\n",
    "                font-weight:700;\n",
    "                font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
    "                }\n",
    "            QPushButton#left_button:hover{border-left:4px solid red;font-weight:700;}\n",
    "        ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "australian-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "from pyaudio import PyAudio\n",
    "import sys\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pypianoroll as pr\n",
    "import pretty_midi\n",
    "import librosa.display\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models  \n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import Parameter\n",
    "import shutil\n",
    "\n",
    "\n",
    "import time, threading\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "restricted-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "    bl = pretty_midi.PrettyMIDI(\"/home/zac3pio1/Music/1.mid\")\n",
    "    wf = bl.fluidsynth(fs = 44100, sf2_path=\"/home/zac3pio1/Documents/lmms/samples/soundfonts/FatBoy-v0.786.sf2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "german-china",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1382604,) 0.8793162393162394 -1.0\n"
     ]
    }
   ],
   "source": [
    "            samples = wf# np.sin(np.arange(50000)/20)\n",
    "            print(samples.shape, samples.max(), samples.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affected-perth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1382604,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            stream.write(samples.astype(np.float32).tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "metallic-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "def player():\n",
    "    chunk = 1024\n",
    "    bl = pretty_midi.PrettyMIDI(\"/home/zac3pio1/Music/1.mid\")\n",
    "    wf = bl.fluidsynth(fs = 44100, sf2_path=\"/home/zac3pio1/Documents/lmms/samples/soundfonts/FatBoy-v0.786.sf2\")\n",
    "\n",
    "    p = PyAudio()\n",
    "  \n",
    "    gplay = True\n",
    "    while 1:\n",
    "        if(gplay):\n",
    "            print(\"play!!!!!!!!\")\n",
    "            stream = p.open(format=pyaudio.paFloat32,\n",
    "                            channels=1,\n",
    "                            rate=44100,\n",
    "                            frames_per_buffer=1024,\n",
    "                            output=True,)\n",
    "            samples = wf# np.sin(np.arange(50000)/20)\n",
    "            print(samples.shape, samples.max(), samples.min())\n",
    "            stream.write(samples.astype(np.float32).tobytes())\n",
    "            stream.close()\n",
    "            gplay = False\n",
    "        else:\n",
    "            print(\"xxxxxxxxxx\", gplay)\n",
    "            time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioThread(QThread, waves):  # 线程1\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stop_flag = False\n",
    "        self.waves = waves\n",
    "        self.stream = p.open(format=pyaudio.paFloat32,\n",
    "                             channels=1,\n",
    "                             rate=44100,\n",
    "                             frames_per_buffer=1024,\n",
    "                             output=True,)\n",
    "    def run(self, ):\n",
    "        for i in range(cur_pixel, self.length):\n",
    "            if(self.stop_flag):\n",
    "                break\n",
    "            stream.write(self.waves[i])\n",
    "        stream.close()\n",
    "        \n",
    "    def stop(self):  \n",
    "        self.stop_flag = True\n",
    "        print('th drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intelligent-spanking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play!!!!!!!!\n",
      "(1382604,) 0.8793162393162394 -1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-0c2235442ae8>:19: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  stream.write(samples.astype(np.float32).tostring())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n",
      "xxxxxxxxxx False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9a7d1c6fa249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-0c2235442ae8>\u001b[0m in \u001b[0;36mplayer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xxxxxxxxxx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgplay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    def mousePressEvent(self, event):\n",
    "        if event.button()==Qt.LeftButton:\n",
    "            self.m_flag=True\n",
    "            self.m_Position=event.globalPos()-self.pos() #获取鼠标相对窗口的位置\n",
    "            event.accept()\n",
    "            self.setCursor(QCursor(Qt.OpenHandCursor))  #更改鼠标图标\n",
    "\n",
    "    def mouseMoveEvent(self, QMouseEvent):\n",
    "        if Qt.LeftButton and self.m_flag:  \n",
    "            self.move(QMouseEvent.globalPos()-self.m_Position)#更改窗口位置\n",
    "            QMouseEvent.accept()\n",
    "\n",
    "    def mouseReleaseEvent(self, QMouseEvent):\n",
    "        self.m_flag=False\n",
    "        self.setCursor(QCursor(Qt.ArrowCursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "governing-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "annual-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse=argparse.ArgumentParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse=argparse.ArgumentParser()\n",
    "\n",
    "parse.add_argument(\"--learning_rate\",type=float,default=0.01,help=\"initial learining rate\")\n",
    "parse.add_argument(\"--max_steps\",type=int,default=2000,help=\"max\")\n",
    "parse.add_argument(\"--hidden1\",type=int,default=100,help=\"hidden1\")\n",
    "program_nums = [24, 2, 26, 87, 89], \n",
    "is_drum = [True, False, False, False, False],\n",
    " tempo=180.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "foster-locking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--program_nums'], dest='program_nums', nargs=None, const=None, default=[24, 2, 26, 87, 89], type=<class 'list'>, choices=None, help='program_nums', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parse.add_argument(\"--program_nums\",type=list,default = [ 24, 2, 26, 87, 89], help=\"program_nums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accomplished-patrick",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ArgumentParser' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1433f05c2069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"program_nums\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'ArgumentParser' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "parse[\"program_nums\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brave-collectible",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--program_nums PROGRAM_NUMS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/zac3pio1/.local/share/jupyter/runtime/kernel-5c0fa05e-7050-4db1-b68c-24a15494c0ad.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zac3pio1/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "arg=parse.parse_args(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "permanent-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"program_nums\" : [24, 2, 26, 87, 89],\n",
    "    \"is_drum\" : [True, False, False, False, False],\n",
    "    \"tempo\" : 180.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "indirect-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_code = [{}, {}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "mounted-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"ins_name\", \"r+\")\n",
    "while(True):\n",
    "    line = fo.readline()\n",
    "    if(len(line) < 1):\n",
    "        break\n",
    "    idx = int(line.split()[0])\n",
    "    name = line[:-1]\n",
    "    track_code[1][idx] = name\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "editorial-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fo = open(\"drum_name\", \"r+\")\n",
    "while(True):\n",
    "    line = fo.readline()\n",
    "    if(len(line) < 1):\n",
    "        break\n",
    "    idx = int(line.split()[0])\n",
    "    name = line[:-1]\n",
    "    track_code[0][idx] = name\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prompt-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "args[\"track_code\"] = track_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "composed-crash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 Acoustic Grand Piano',\n",
       " '1 Bright Acoustic Piano ',\n",
       " '2 Electric Grand Piano',\n",
       " '3 Honky-tonk Piano ',\n",
       " '4 Rhodes Piano',\n",
       " '5 Chorused Piano',\n",
       " '6 Harpsichord',\n",
       " '16 Hammond Organ',\n",
       " '17 Percussive Organ 打击式风琴',\n",
       " '18 Rock Organ 摇滚风琴',\n",
       " '19 Church Organ 教堂风琴',\n",
       " '20 Reed Organ 簧管风琴',\n",
       " '21 Accordian 手风琴',\n",
       " '22 Harmonica 口琴',\n",
       " '23 Tango Accordian',\n",
       " '24 Acoustic Guitar',\n",
       " '25 Acoustic Guitar (steel) 钢弦吉他',\n",
       " '26 Electric Guitar (jazz) 爵士电吉他',\n",
       " '27 Electric Guitar (clean) 清音电吉他',\n",
       " '28 Electric Guitar (muted) 闷音电吉他',\n",
       " '29 Overdriven Guitar 加驱动效果的电吉他',\n",
       " '30 Distortion Guitar 加失真效果的电吉他',\n",
       " '31 Guitar Harmonics 吉他和音',\n",
       " '32 Acoustic Bass',\n",
       " '33 Electric Bass(finger)',\n",
       " '34 Electric Bass(pick)',\n",
       " '35 Fretless Bass 无品贝司',\n",
       " '36 Slap Bass 1',\n",
       " '37 Slap Bass 2 ',\n",
       " '39 Synth Bass 2',\n",
       " '40 Violin',\n",
       " '41 Viola 中提琴',\n",
       " '42 Cello 大提琴',\n",
       " '43 Contrabass 低音大提琴',\n",
       " '44 Tremolo Strings 弦乐群颤音音色',\n",
       " '45 Pizzicato Strings 弦乐群拨弦音色',\n",
       " '46 Orchestral Harp 竖琴',\n",
       " '47 Timpani',\n",
       " '48 String Ensemble 1',\n",
       " '49 String Ensemble 2 ',\n",
       " '50 Synth Strings 1',\n",
       " '51 Synth Strings 2',\n",
       " '52 Choir Aahs',\n",
       " '53 Voice Oohs ',\n",
       " '54 Synth Voice ',\n",
       " '55 Orchestra Hit ',\n",
       " '56 Trumpet',\n",
       " '57 Trombone 长号',\n",
       " '58 Tuba 大号',\n",
       " '62 Synth Brass 1 合成铜管音色1',\n",
       " '63 Synth Brass 2',\n",
       " '64 Soprano Sax',\n",
       " '65 Alto Sax ',\n",
       " '66 Tenor Sax',\n",
       " '67 Baritone Sax ',\n",
       " '68 Oboe',\n",
       " '69 English Horn 英国管',\n",
       " '70 Bassoon 巴松（大管）',\n",
       " '71 Clarinet',\n",
       " '72 Piccolo',\n",
       " '73 Flute 长笛',\n",
       " '74 Recorder 竖笛',\n",
       " '75 Pan Flute',\n",
       " '76 Bottle Blow',\n",
       " '79 Ocarina 奥卡雷那',\n",
       " '80 Lead 1 (square)',\n",
       " '81 Lead 2 (sawtooth)',\n",
       " '82 Lead 3 (caliope lead) ',\n",
       " '83 Lead 4 (chiff lead) ',\n",
       " '84 Lead 5',\n",
       " '85 Lead 6 (voice) 合成主音6（人声）',\n",
       " '86 Lead 7（平行五度）',\n",
       " '87 Lead 8 (bass+lead)合成主音8（贝司加主音）',\n",
       " '88 Pad 1 (new age)',\n",
       " '89 Pad 2 (warm) 合成音色2 （温暖）',\n",
       " '90 Pad 3 (polysynth)',\n",
       " '91 Pad 4 (choir) ',\n",
       " '92 Pad 5 (bowed)',\n",
       " '93 Pad 6 (metallic) 合成音色6',\n",
       " '94 Pad 7 (halo)',\n",
       " '95 Pad 8 (sweep) 合成音色8']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(args[\"track_code\"][1].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "complimentary-riverside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0 Standard Set',\n",
       " 8: '8 Room Set',\n",
       " 16: '16 Power Set',\n",
       " 24: '24 Electronic Set',\n",
       " 25: '25 TR-808 Set',\n",
       " 32: '32 Jazz Set',\n",
       " 118: '118 FSM',\n",
       " 127: '127 CM-32/32L Set'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[\"track_code\"][False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radio-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pypianoroll as pr\n",
    "import pretty_midi\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.models as models  \n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.utils import spectral_norm\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import Parameter\n",
    "import shutil\n",
    "from util import *\n",
    "import time\n",
    "import qtawesome\n",
    "import sys\n",
    "\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FC\n",
    "class MCheckBox(QCheckBox):\n",
    "  def __init__(self, idx, param):\n",
    "    QCheckBox.__init__(self, param)\n",
    "    #设置标题与初始大小\n",
    "    self.id = idx\n",
    "\n",
    "class Box(QWidget):\n",
    "    def __init__(self, args):\n",
    "        \n",
    "        self.args = args\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "        self.init_timer()\n",
    "        self.init_lt()\n",
    "    def initUI(self):\n",
    "        \n",
    "        self.setWindowTitle('DEMO')\n",
    "        self.resize(1400,800)\n",
    "        self.thr = 0.5\n",
    "        self.n_tracks = 5\n",
    "        \n",
    "        #main layout\n",
    "        layout   = QGridLayout()\n",
    "        #top layout\n",
    "        top_widget = QWidget()\n",
    "        layout_top = QGridLayout()\n",
    "        top_widget.setLayout(layout_top)\n",
    "        #bottom layout\n",
    "        bottom_widget = QWidget()\n",
    "        layout_bottom = QGridLayout()\n",
    "        bottom_widget.setLayout(layout_bottom)\n",
    "        \n",
    "        \n",
    "        #track config layout\n",
    "        tracks = QWidget()\n",
    "        layout_tracks = QGridLayout()\n",
    "        #layout_trackconfig = QGridLayout()\n",
    "        tracks.setLayout(layout_tracks)\n",
    "        #adding widget for each track        \n",
    "        self.track_checkboxL = []\n",
    "        self.track_comboboxL = []\n",
    "        for i in range(self.n_tracks):\n",
    "          track = QWidget()\n",
    "          not_drum = not self.args[\"is_drum\"][i]\n",
    "          layout_track_cur = QGridLayout()\n",
    "          track.setLayout(layout_track_cur)\n",
    "          \n",
    "          #checkbox\n",
    "          checkbox = MCheckBox(i, self)\n",
    "          checkbox.setChecked(True)\n",
    "          checkbox.setText(\"Track \" + str(i))\n",
    "          layout_track_cur.addWidget(checkbox, 0, 0, 1, 1)\n",
    "          checkbox.stateChanged.connect(self.checkbox_conn)\n",
    "          self.track_checkboxL.append(checkbox)\n",
    "\n",
    "          #combobox\n",
    "          combobox = QComboBox(self)\n",
    "          layout_track_cur.addWidget(combobox, 0, 1, 1, 2)\n",
    "          combobox.addItems(self.args[\"track_code\"][not_drum].values())\n",
    "          combobox.currentIndexChanged[str].connect(self.print_value) # 条目发生改变，发射信号，传递条目内容\n",
    "          combobox.currentIndexChanged[int].connect(self.print_value)  # 条目发生改变，发射信号，传递条目索引\n",
    "          combobox.highlighted[str].connect(self.print_value)  # 在下拉列表中，鼠标移动到某个条目时发出信号，传递条目内容\n",
    "          combobox.highlighted[int].connect(self.print_value) \n",
    "          self.track_comboboxL.append(combobox)\n",
    "          combobox.addItems\n",
    "\n",
    "\n",
    "          layout_tracks.addWidget(track, i, 0, 1, 1)\n",
    "                    \n",
    "\n",
    "        #init canvas\n",
    "        self.init_canvas()\n",
    "        \n",
    "        self.init_progressbar()\n",
    "        \n",
    "        self.content = QLabel(self)\n",
    "        \n",
    "        layout_top.addWidget(tracks,       0, 0, 10,  4)\n",
    "        layout_top.addWidget(self.content, 0, 4, 10,  8)        \n",
    "        layout_top.addWidget(self.canvas , 0, 8, 10, 14)\n",
    "        \n",
    "        layout_bottom.addWidget(self.process_bar, 9, 0, 1, 9)\n",
    "        layout_bottom.addWidget(self.playconsole_widget, 10, 0, 1, 9)\n",
    "        \n",
    "        layout.addWidget(top_widget,       0, 0, 3,  1) \n",
    "        layout.addWidget(bottom_widget,    3, 0, 4,  1)     \n",
    "        self.setLayout(layout)\n",
    "        self.show()\n",
    "    def init_progressbar(self):\n",
    "      self.process_bar = QSlider(Qt.Horizontal)  # 播放进度部件\n",
    "      #self.process_bar = QProgressBar()  # 播放进度部件\n",
    "      self.process_bar.setFixedHeight(4)  # 设置进度条高度\n",
    "      #self.process_bar.setTextVisible(False)  # 不显示进度条文字\n",
    "      self.process_bar.setValue(10)\n",
    "      \n",
    "      self.process_bar.setMinimum(0)\n",
    "      self.process_bar.setMaximum(384)\n",
    "      self.process_bar.setSingleStep(1)\n",
    "    \n",
    "      self.process_bar.sliderReleased.connect(self.process_bar_control)\n",
    "      #self.process_bar.sliderPressed.connect(self.process_bar_control)\n",
    "      self.playconsole_widget = QWidget()  # 播放控制部件\n",
    "      self.playconsole_layout = QGridLayout()  # 播放控制部件网格布局层\n",
    "      self.playconsole_widget.setLayout(self.playconsole_layout)\n",
    "      self.console_button_1 = QPushButton(qtawesome.icon('fa.play-circle', color='#F76677', font=18), \"\")\n",
    "      self.console_button_2 = QPushButton(qtawesome.icon('fa.headphones', color='#F76677', font=16), \"\")\n",
    "      self.console_button_3 = QPushButton()\n",
    "      self.console_button_1.setIconSize(QSize(30, 30))\n",
    "      self.playconsole_layout.addWidget(self.console_button_1, 0, 0)\n",
    "      self.playconsole_layout.addWidget(self.console_button_2, 0, 1)\n",
    "      self.playconsole_layout.addWidget(self.console_button_3, 0, 2)\n",
    "      self.playconsole_layout.setAlignment(Qt.AlignCenter)  # 设置布局内部件居中显示\n",
    "    def process_bar_control(self):\n",
    "      print('current slider value=%s'%self.process_bar.value())\n",
    "      pass\n",
    "    def init_canvas(self):\n",
    "        self.fig, self.ax = plt.subplots(figsize=(20, 30), tight_layout = True)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        self.fig.subplots_adjust(top=1,bottom=0,left=0,right=1,hspace=0,wspace=0)\n",
    "        self.ax.axes.set_axis_off()\n",
    "        self.canvas = FC(self.fig)\n",
    "\n",
    "        self.ax.cla() # TODO:删除原图，让画布上只有新的一次的图\n",
    "        self.paino_roll = np.zeros([72 * 5, 384 * 3], np.float32)\n",
    "        self.paino_roll[:, 100: 102] = 1\n",
    "        \n",
    "        self.ax.imshow(self.paino_roll)\n",
    "        #self.ax.imshow(self.fake[:, :, :, 0].reshape(self.fake.shape[0] * self.fake.shape[1], self.fake.shape[2],).transpose([1, 0]) > self.thr)\n",
    "        self.canvas.draw() # TODO:这里开始绘制\n",
    "        \n",
    "        \n",
    "    def init_lt(self):\n",
    "        self.ntimer = QTimer()\n",
    "        self.ntimer.setInterval(1000)\n",
    "        self.ntimer.start()\n",
    "        self.ntimer.timeout.connect(self.update_time)\n",
    "    def update_time(self):\n",
    "        #self.content.setText(time.strftime(\"%X\", time.localtime()))\n",
    "        pass\n",
    "    def init_timer(self):\n",
    "        self.timer = QTimer()\n",
    "        self.timer.setInterval(200)\n",
    "        self.timer.start()\n",
    "        self.timer.timeout.connect(self.update_canvas)\n",
    "\n",
    "    def update_canvas(self):\n",
    "        pixel_gap = 1\n",
    "        self.paino_roll[:, :-pixel_gap] = self.paino_roll[:, pixel_gap: ]\n",
    "        self.ax.cla() # TODO:删除原图，让画布上只有新的一次的图\n",
    "        self.ax.imshow(self.paino_roll)\n",
    "        self.canvas.draw() # TODO:这里开始绘制\n",
    "        self.process_bar.setValue(self.process_bar.value() + 1)\n",
    "        pass\n",
    "    def print_value(self, i):\n",
    "        print(i)\n",
    "    def checkbox_conn(self):\n",
    "        text = \"\"\n",
    "        for i in range(self.n_tracks):\n",
    "            choice = str(self.track_checkboxL[i].id) if self.track_checkboxL[i].isChecked() else ''\n",
    "            print(i, self.track_checkboxL[i].isChecked())\n",
    "            text += choice\n",
    "        print(text)\n",
    "        self.content.setText(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affected-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "?QComboBox.setCurrentIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worthy-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from ipywidgets import interact, IntSlider\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "from pathlib import Path\n",
    "import math\n",
    "import IPython.display\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track\n",
    "from tqdm.notebook import tqdm\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proof-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() ) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conceptual-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfea = 16\n",
    "latent_v_dim = 32\n",
    "n_fc = 6\n",
    "n_verses = 6\n",
    "latent_w = 4\n",
    "latent_h = 6\n",
    "batch_size = 32\n",
    "latent_dim = 8\n",
    "embedding_dim = latent_dim\n",
    "\n",
    "num_embeddings = 2048\n",
    "\n",
    "\n",
    "commitment_cost = 0.25\n",
    "decay = 0.99\n",
    "\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "favorite-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"program_nums\"   :   [3, 2, 17, 72, 74],\n",
    "    \"is_drum\"        :   [True, False, False, False, False],\n",
    "    \"tempo\"          :  180.0,\n",
    "    \"n_tracks\"       :    5,\n",
    "    \"n_pitches\"      :   72,\n",
    "    \"lowest_pitch\"   :   24,\n",
    "    \"n_measures\"     :    4,\n",
    "    \"beat_resolution\":    4,\n",
    "    \"batch_size\"     :    1,\n",
    "    \"decay\"          :    0.99,\n",
    "    \"commitment_cost\":    0.25,\n",
    "    \"latent_dim\"     :    8,\n",
    "    \"embedding_dim\"  :    8,\n",
    "    \"num_embeddings\" : 2048,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessible-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedConv3d(torch.nn.Conv3d):\n",
    "    def __init__(self, mask_type, *args, **kwargs):\n",
    "        super(MaskedConv3d, self).__init__(*args, **kwargs)\n",
    "        assert mask_type in {'A', 'B'}\n",
    "        self.register_buffer('mask', self.weight.data.clone())\n",
    "        _, _, kI, kP, kT = self.weight.size()\n",
    "        self.mask.fill_(1)\n",
    "        self.mask[:, :, :, :, kT - 1 + (mask_type == 'B'):] = 0\n",
    "    def forward(self, x):\n",
    "        self.weight.data *= self.mask\n",
    "        return super(MaskedConv3d, self).forward(x)\n",
    "class MaskBlock(torch.nn.Module):\n",
    "    def __init__(self, mask_type, in_dim, out_dim, kernel):\n",
    "        super().__init__()\n",
    "        self.n_tracks = 5\n",
    "        self.n_classes = 6\n",
    "        self.kernel = kernel\n",
    "        self.out_dim = out_dim\n",
    "        self.padding = kernel - 1\n",
    "        self.conv0 = torch.nn.Conv3d(in_dim , out_dim * self.n_classes, (1, self.n_classes, 1), 1, 0, bias=False)\n",
    "        self.conv1 = torch.nn.Conv3d(out_dim, out_dim *  self.n_tracks, (1, self.n_tracks, 1),       1, 0, bias=False)\n",
    "        self.maskconv = MaskedConv3d(mask_type ,\n",
    "                                     out_dim, out_dim                 , (1, 1, kernel),  1, (0, 0, self.padding), bias=False)\n",
    "        self.batchnorm = torch.nn.BatchNorm3d(out_dim)\n",
    "        self.relu = torch.nn.ReLU(True)\n",
    "    def forward(self, x):\n",
    "        x_shape = x.shape\n",
    "        x = self.conv0(x)\n",
    "        x = x.view(x_shape[0], self.out_dim, self.n_classes , x_shape[2], x_shape[4])\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(x_shape[0], self.out_dim, self.n_tracks , self.n_classes, x_shape[4])\n",
    "        x = self.maskconv(x)\n",
    "        x = x[:, :, :, :, : -(self.kernel - 1)].view(x_shape[0], self.out_dim, x_shape[2], x_shape[3], x_shape[4])\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class PIXELCNN(torch.nn.Module):\n",
    "    # 1 chanel PixelCNN\n",
    "    def __init__(self, k_dim, z_dim, kernel_size=3, fm=32):\n",
    "        super(PIXELCNN, self).__init__()\n",
    "        self.k_dim = k_dim\n",
    "        self.z_dim = z_dim\n",
    "        self.fm = fm\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size\n",
    "        self.latent_p = 6\n",
    "        self.conv0 = MaskBlock('A', self.z_dim, self.fm, kernel_size)\n",
    "        self.num_b_conv = 7\n",
    "        self.conv1 = torch.nn.ModuleList([\n",
    "            torch.nn.Sequential(\n",
    "                MaskBlock('B', self.fm, self.fm, kernel_size),\n",
    "            ) for _ in range(self.num_b_conv)\n",
    "        ])\n",
    "        self.conv2 = torch.nn.Conv3d(self.fm, self.k_dim, 1, 1, 0)\n",
    "        \n",
    "\n",
    "    def forward(self, z):\n",
    "        x_shape = z.shape\n",
    "        x = self.conv0(z)\n",
    "        for i in range(self.num_b_conv):\n",
    "            x = self.conv1[i](x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "boring-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class GeneraterBlock(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
    "        super().__init__()\n",
    "        self.transconv = torch.nn.ConvTranspose3d(in_dim, out_dim, kernel, stride)\n",
    "        self.batchnorm = torch.nn.BatchNorm3d(out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transconv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        return torch.nn.functional.relu(x)\n",
    "\n",
    "\n",
    "class Bar_Decoder(torch.nn.Module):\n",
    "    \"\"\"A convolutional neural network (CNN) based generator. The generator takes\n",
    "    as input a latent vector and outputs a fake sample.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # \n",
    "        self.transconv0 = GeneraterBlock(latent_dim, nfea * 8, (1, 1, 1), (1, 1, 1))\n",
    "        self.transconv1 = GeneraterBlock(nfea * 8, nfea *  4, (1, 4, 1), (1, 4, 1))\n",
    "        self.transconv2 = GeneraterBlock(nfea *  4, nfea *  2, (1, 1, 3), (1, 1, 3))\n",
    "        self.transconv3 = GeneraterBlock(nfea *  2, nfea *  1, (1, 4, 1), (1, 4, 1))\n",
    "        self.transconv4 = torch.nn.ConvTranspose3d(nfea *  1,         1, (1, 1, 4), (1, 1, 4))\n",
    "        layers = []\n",
    "        for i in range(4):\n",
    "            layers.append(torch.nn.Linear(latent_dim, latent_dim))\n",
    "            layers.append(torch.nn.LeakyReLU(0.2))\n",
    "        self.mapping = torch.nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        #merge latent\n",
    "        x = x.view(-1, latent_dim, latent_w, 1, latent_h)\n",
    "        x = x.permute(0, 2, 3, 4, 1).contiguous()\n",
    "        x_shape = x.shape\n",
    "        flat_x = x.view(-1, latent_dim)\n",
    "        flat_x = self.mapping(flat_x)\n",
    "        x = flat_x.view(x_shape)\n",
    "        x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
    "        \n",
    "        \n",
    "        x = self.transconv0(x)\n",
    "        x = self.transconv1(x)\n",
    "        x = self.transconv2(x)\n",
    "        x = self.transconv3(x)\n",
    "        x = self.transconv4(x)\n",
    "        x = x.view(-1,  n_measures * measure_resolution, n_pitches)\n",
    "        return x\n",
    "\n",
    "class LayerNorm(torch.nn.Module):\n",
    "    \"\"\"An implementation of Layer normalization that does not require size\n",
    "    information. Copied from https://github.com/pytorch/pytorch/issues/1959.\"\"\"\n",
    "    def __init__(self, n_features, eps=1e-5, affine=True):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "        if self.affine:\n",
    "            self.gamma = torch.nn.Parameter(torch.Tensor(n_features).uniform_())\n",
    "            self.beta = torch.nn.Parameter(torch.zeros(n_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = [-1] + [1] * (x.dim() - 1)\n",
    "        mean = x.view(x.size(0), -1).mean(1).view(*shape)\n",
    "        std = x.view(x.size(0), -1).std(1).view(*shape)\n",
    "        y = (x - mean) / (std + self.eps)\n",
    "        if self.affine:\n",
    "            shape = [1, -1] + [1] * (x.dim() - 2)\n",
    "            y = self.gamma.view(*shape) * y + self.beta.view(*shape)\n",
    "        return y\n",
    "class CompressBlock(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
    "        super().__init__()\n",
    "        self.transconv = torch.nn.Conv3d(in_dim, out_dim, kernel, stride)\n",
    "        self.layernorm = LayerNorm(out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transconv(x)\n",
    "        x = self.layernorm(x)\n",
    "        return torch.nn.functional.leaky_relu(x)\n",
    "class Bar_Encoder(torch.nn.Module):\n",
    "    \"\"\"A convolutional neural network (CNN) based discriminator. The\n",
    "    discriminator takes as input either a real sample (in the training data) or\n",
    "    a fake sample (generated by the generator) and outputs a scalar indicating\n",
    "    its authentity.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = CompressBlock(        1, nfea *  1, (1, 1, 4), (1, 1, 4)) \n",
    "        self.conv1 = CompressBlock(nfea *  1, nfea *  2, (1, 4, 1), (1, 4, 1))\n",
    "        self.conv2 = CompressBlock(nfea *  2, nfea *  4, (1, 1, 3), (1, 1, 3))\n",
    "        self.conv3 = CompressBlock(nfea *  4, nfea * 8, (1, 4, 1), (1, 4, 1))\n",
    "        self.conv4 = torch.nn.Conv3d(nfea * 8, latent_dim, (1, 1, 1), (1, 1, 1))\n",
    "        layers = []\n",
    "        for i in range(3):\n",
    "            layers.append(torch.nn.Linear(latent_dim, latent_dim))\n",
    "            layers.append(torch.nn.LeakyReLU(0.2))\n",
    "        layers.append(torch.nn.Linear(latent_dim, latent_dim))\n",
    "        self.mapping = torch.nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, n_measures, measure_resolution, n_pitches)\n",
    "\n",
    "        x = self.conv0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)         \n",
    "        x = self.conv4(x)\n",
    "\n",
    "        x = x.permute(0, 2, 3, 4, 1).contiguous()\n",
    "        x_shape = x.shape\n",
    "        flat_x = x.view(-1, latent_dim)\n",
    "        flat_x = self.mapping(flat_x)\n",
    "        x = flat_x.view(x_shape)\n",
    "        x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
    "        x = x.view(-1, latent_dim, latent_w, latent_h)\n",
    "        return x\n",
    "\n",
    "class VectorQuantizer(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = torch.nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n",
    "        self._commitment_cosmeasure_resolutiont = commitment_cost\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "            + torch.sum(self._embedding.weight**2, dim=1)\n",
    "            - 2 * torch.matmul(flat_input, self._embedding.weight.t()))    \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argminDecoder(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings\n",
    "class VectorQuantizerEMA(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, decay, epsilon=1e-5):\n",
    "        super(VectorQuantizerEMA, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = torch.nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.normal_()\n",
    "        self._commitment_cost = commitment_cost\n",
    "        \n",
    "        self.register_buffer('_ema_cluster_size', torch.zeros(num_embeddings))\n",
    "        self._ema_w = torch.nn.Parameter(torch.Tensor(num_embeddings, self._embedding_dim))\n",
    "        self._ema_w.data.normal_()\n",
    "        \n",
    "        self._decay = decay\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        # Use EMA to update the embedding vectors\n",
    "        if self.training:\n",
    "            self._ema_cluster_size = self._ema_cluster_size * self._decay + \\\n",
    "                                     (1 - self._decay) * torch.sum(encodings, 0)\n",
    "            \n",
    "            # Laplace smoothing of the cluster size\n",
    "            n = torch.sum(self._ema_cluster_size.data)\n",
    "            self._ema_cluster_size = (\n",
    "                (self._ema_cluster_size + self._epsilon)\n",
    "                / (n + self._num_embeddings * self._epsilon) * n)\n",
    "            \n",
    "            dw = torch.matmul(encodings.t(), flat_input)\n",
    "            self._ema_w = torch.nn.Parameter(self._ema_w * self._decay + (1 - self._decay) * dw)\n",
    "            \n",
    "            self._embedding.weight = torch.nn.Parameter(self._ema_w / self._ema_cluster_size.unsqueeze(1))\n",
    "        \n",
    "        # Loss\n",
    "\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        loss = self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        # Straight Through Estimator\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        encodings = encodings.view(input_shape[0], input_shape[1], input_shape[2], self._num_embeddings).permute(0, 3, 1, 2).contiguous()\n",
    "        \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        return loss, quantized.permute(0, 3, 1, 2).contiguous(), perplexity, encodings\n",
    "        \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, commitment_cost, decay=0):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.encoder = Bar_Encoder()\n",
    "        if decay > 0.0:\n",
    "            self.VQ = VectorQuantizerEMA(num_embeddings, embedding_dim, \n",
    "                                              commitment_cost, decay)\n",
    "\n",
    "        else:\n",
    "            self.VQ = VectorQuantizer(num_embeddings, embedding_dim, \n",
    "                                              commitment_cost, decay)\n",
    "            \n",
    "        self.decoder = Bar_Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        loss, z_q, perplexity, _ = self.VQ(z)\n",
    "        x_recon = self.decoder(z_q)\n",
    "        return loss, x_recon, perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "superb-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vital-modem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize step\n",
    "\n",
    "model = Model(commitment_cost, decay).to(device)\n",
    "check_path = 'musevqvae.pth'\n",
    "checkpoint = torch.load(check_path)\n",
    "model.load_state_dict(checkpoint['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "empirical-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pixelcnn = PIXELCNN(k_dim=num_embeddings,z_dim=embedding_dim).to(device)\n",
    "check_path = 'tripixelcnn.pth'\n",
    "checkpoint = torch.load(check_path)\n",
    "pixelcnn.load_state_dict(checkpoint['model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "weird-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-marble",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
